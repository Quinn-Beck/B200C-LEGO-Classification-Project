{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import squeezenet1_1, resnet50, densenet201\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from preprocessing_pipeline import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:11<00:00, 1083.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_data(num_classes=num_classes)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [06:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Batch: 0 / Epoch: 0 / Loss: 1.9132 / Pred:tensor([3.1362, 3.9493, 5.1024], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100 / Epoch: 0 / Loss: 0.9641 / Pred:tensor([1.1034, 3.3354, 1.9352], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 0 / Loss: 0.7433 / Pred:tensor([2.6188, 0.2852, 2.0602], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 2/20\n",
      "Batch: 0 / Epoch: 1 / Loss: 0.5441 / Pred:tensor([7.8896, 0.0409, 3.3976], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 1 / Loss: 0.5054 / Pred:tensor([5.7580, 0.7011, 0.9782], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 1 / Loss: 0.5552 / Pred:tensor([0.2149, 3.6262, 0.5827], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 3/20\n",
      "Batch: 0 / Epoch: 2 / Loss: 0.4669 / Pred:tensor([0.2593, 6.8310, 1.0293], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 2 / Loss: 0.3665 / Pred:tensor([7.0009, 0.1938, 1.4598], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 2 / Loss: 0.3184 / Pred:tensor([7.3259, 0.0000, 1.8489], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 4/20\n",
      "Batch: 0 / Epoch: 3 / Loss: 0.2881 / Pred:tensor([0.9997, 1.5624, 1.5205], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 3 / Loss: 0.2181 / Pred:tensor([0.7107, 6.4289, 2.7569], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 3 / Loss: 0.0731 / Pred:tensor([0.1512, 6.9318, 1.7558], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 5/20\n",
      "Batch: 0 / Epoch: 4 / Loss: 0.2924 / Pred:tensor([0.4083, 7.6509, 3.2563], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 4 / Loss: 0.2701 / Pred:tensor([2.8829, 6.9831, 0.0331], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 4 / Loss: 0.2297 / Pred:tensor([1.7054, 4.4257, 4.4539], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 6/20\n",
      "Batch: 0 / Epoch: 5 / Loss: 0.2790 / Pred:tensor([0.9943, 1.6110, 5.5927], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 5 / Loss: 0.1614 / Pred:tensor([7.0041, 0.1681, 4.1434], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 5 / Loss: 0.1136 / Pred:tensor([2.8612, 0.3797, 8.8852], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 7/20\n",
      "Batch: 0 / Epoch: 6 / Loss: 0.4851 / Pred:tensor([1.3873, 6.5777, 5.5762], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 6 / Loss: 0.0819 / Pred:tensor([9.8259, 0.0000, 3.0897], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 6 / Loss: 0.0493 / Pred:tensor([4.6524, 2.0769, 7.9088], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 8/20\n",
      "Batch: 0 / Epoch: 7 / Loss: 0.0940 / Pred:tensor([ 2.4274, 12.7776,  0.9067], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 7 / Loss: 0.1354 / Pred:tensor([4.4863, 0.8431, 8.2506], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 7 / Loss: 0.0500 / Pred:tensor([0.6681, 5.6682, 4.5779], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 9/20\n",
      "Batch: 0 / Epoch: 8 / Loss: 0.1769 / Pred:tensor([7.6397, 1.4462, 3.3888], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 8 / Loss: 0.0574 / Pred:tensor([ 3.6653, 11.8344,  1.8190], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 8 / Loss: 0.0254 / Pred:tensor([11.7176,  0.8672,  3.9212], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 10/20\n",
      "Batch: 0 / Epoch: 9 / Loss: 0.0258 / Pred:tensor([ 1.0173,  1.3046, 12.5910], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 9 / Loss: 0.0170 / Pred:tensor([ 5.6273, 13.7285,  2.2335], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 9 / Loss: 0.1805 / Pred:tensor([ 6.3452,  4.9187, 11.2855], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 11/20\n",
      "Batch: 0 / Epoch: 10 / Loss: 0.0722 / Pred:tensor([ 2.5091, 16.4521,  1.3281], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 10 / Loss: 0.0238 / Pred:tensor([ 2.6584, 12.3153,  1.3173], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 10 / Loss: 0.0553 / Pred:tensor([ 1.2714, 14.0849,  2.4795], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 12/20\n",
      "Batch: 0 / Epoch: 11 / Loss: 0.0495 / Pred:tensor([1.4840, 2.0674, 9.4361], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 11 / Loss: 0.4605 / Pred:tensor([ 2.5943,  2.0266, 11.5128], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 11 / Loss: 0.0520 / Pred:tensor([1.3658, 8.5000, 2.0600], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 13/20\n",
      "Batch: 0 / Epoch: 12 / Loss: 0.0289 / Pred:tensor([1.6939, 8.7695, 3.4194], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 12 / Loss: 0.0424 / Pred:tensor([1.9734, 0.7060, 9.9639], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 12 / Loss: 0.1474 / Pred:tensor([4.3947, 7.0470, 3.2227], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 14/20\n",
      "Batch: 0 / Epoch: 13 / Loss: 0.0384 / Pred:tensor([ 5.2837, 11.4663,  6.7817], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 13 / Loss: 0.0855 / Pred:tensor([ 1.9560,  0.7260, 11.7181], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 13 / Loss: 0.0511 / Pred:tensor([10.6062,  0.0000,  2.0670], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 15/20\n",
      "Batch: 0 / Epoch: 14 / Loss: 0.0901 / Pred:tensor([2.3460, 1.7645, 8.6664], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 14 / Loss: 0.0465 / Pred:tensor([ 4.1494,  2.5859, 11.6663], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 14 / Loss: 0.0060 / Pred:tensor([ 1.6952,  2.3718, 13.7792], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 16/20\n",
      "Batch: 0 / Epoch: 15 / Loss: 0.0717 / Pred:tensor([14.4571,  0.0000,  5.0287], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 15 / Loss: 0.0158 / Pred:tensor([ 4.1841, 10.0949,  2.2427], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 15 / Loss: 0.0128 / Pred:tensor([13.1258,  0.0000,  2.3265], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 17/20\n",
      "Batch: 0 / Epoch: 16 / Loss: 0.0191 / Pred:tensor([ 1.7797, 15.3859,  1.4245], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 16 / Loss: 0.0038 / Pred:tensor([11.0695,  2.8351,  2.8412], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 16 / Loss: 0.0824 / Pred:tensor([ 7.8197, 15.4210,  3.7430], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 18/20\n",
      "Batch: 0 / Epoch: 17 / Loss: 0.0182 / Pred:tensor([ 3.6540,  1.7780, 10.3204], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 17 / Loss: 0.0823 / Pred:tensor([5.0630, 3.2279, 2.1447], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 17 / Loss: 0.0290 / Pred:tensor([11.6287,  0.0000,  3.7479], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 19/20\n",
      "Batch: 0 / Epoch: 18 / Loss: 0.0208 / Pred:tensor([ 1.4412,  0.5759, 12.3510], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 18 / Loss: 0.0246 / Pred:tensor([10.0004,  0.0000,  3.3060], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 18 / Loss: 0.0017 / Pred:tensor([ 4.2366, 13.0526,  1.7050], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch 20/20\n",
      "Batch: 0 / Epoch: 19 / Loss: 0.0833 / Pred:tensor([ 5.1616,  0.0000, 16.1462], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 100 / Epoch: 19 / Loss: 0.0276 / Pred:tensor([ 2.7045,  0.2804, 17.3932], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Batch: 200 / Epoch: 19 / Loss: 0.0537 / Pred:tensor([9.9674, 3.1365, 3.4637], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "squeezenet_model = squeezenet1_1(weights='DEFAULT')\n",
    "squeezenet_model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "squeezenet_model.num_classes = num_classes\n",
    "squeezenet_model = squeezenet_model.to(device)\n",
    "\n",
    "print(next(squeezenet_model.parameters()).device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=squeezenet_model.parameters(), lr = 1e-5)\n",
    "\n",
    "training_loss = []\n",
    "num_epochs = 20\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for i, (b_x, b_y) in enumerate(train_dataloader):\n",
    "        # load data to gpu\n",
    "        b_x = b_x.to(device)\n",
    "        b_y = b_y.to(device)\n",
    "        \n",
    "        y_pred = squeezenet_model(b_x)\n",
    "        loss = loss_fn(y_pred, b_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # progress_bar.update(1)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            training_loss.append(loss.item())\n",
    "            print(f\"Batch: {i} / Epoch: {epoch} / Loss: {loss.item():.4f} / Pred:{y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x, 1)\n",
    "        \n",
    "        total += x.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Pred: {x} / True: {labels}\")\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: tensor([[11.5583,  1.3501,  3.8475],\n",
      "        [10.9674,  0.0000,  7.3296],\n",
      "        [ 2.7736,  0.0000, 10.9558],\n",
      "        [ 2.4385,  2.9353,  9.2993],\n",
      "        [11.4846,  0.2722,  3.9848],\n",
      "        [ 3.0937,  0.7231, 20.3247],\n",
      "        [ 4.3358,  5.3869, 10.7116],\n",
      "        [ 2.0977,  1.1553, 11.8016],\n",
      "        [ 1.3471,  1.3132, 16.0823],\n",
      "        [ 4.4009,  3.7499, 21.0649],\n",
      "        [ 4.5328, 12.7887,  0.4928],\n",
      "        [ 8.3177,  2.5135,  4.8718],\n",
      "        [ 1.6772,  0.8711, 14.2273],\n",
      "        [ 4.8196, 14.5257,  4.3074],\n",
      "        [ 3.3409,  1.1962, 19.3875],\n",
      "        [ 7.5941, 18.9709,  2.1439],\n",
      "        [ 2.6958, 12.3721,  0.9817],\n",
      "        [ 3.0802,  0.7648, 15.0735],\n",
      "        [ 2.5445,  2.8574, 12.0561],\n",
      "        [18.6187,  0.0000,  3.3410],\n",
      "        [17.0872,  0.0000,  4.3105],\n",
      "        [ 5.9323, 16.5959,  1.1664],\n",
      "        [13.3630,  0.1723,  4.1763],\n",
      "        [ 4.1997, 11.1540,  2.9674],\n",
      "        [18.3207,  0.0000,  4.9398],\n",
      "        [17.9952,  0.6253,  1.0803],\n",
      "        [ 1.7773,  2.5519, 18.4166],\n",
      "        [ 0.7917,  0.2361, 18.9734],\n",
      "        [16.1238,  0.4380,  6.3243],\n",
      "        [ 1.4897,  9.5036,  1.5332],\n",
      "        [ 6.8646, 15.0062,  3.6433],\n",
      "        [ 2.2286,  8.2007,  3.9306]], device='cuda:0', grad_fn=<ViewBackward0>) / True: tensor([0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 1, 1, 2, 2, 0, 0, 1, 0, 1,\n",
      "        0, 0, 2, 2, 0, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9775, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(squeezenet_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
